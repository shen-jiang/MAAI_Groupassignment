{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import _name_estimators\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "\n",
    "import xgboost\n",
    "\n",
    "import time\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None  # To ignore SettingWithCopyWarning warning\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "# Set a random seed for repeatability\n",
    "rand_seed = 100\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "validation = pd.read_csv(\"validation.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# The validation Y refers to the click column of the original validation set\n",
    "val_Y = validation.click\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy data\n",
    "train_X = joblib.load(\"pCTR_X_train_resampled.pkl\")\n",
    "train_Y = joblib.load(\"pCTR_y_train_resampled.pkl\")\n",
    "val_X = joblib.load(\"pCTR_X_validation.pkl\")\n",
    "test_X = joblib.load(\"pCTR_X_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303375, 829)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 829), (40000,), (303925,), (303925, 829), (303375, 829))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the dataset shape\n",
    "train_X.shape, train_Y.shape, val_Y.shape, val_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear Bidding Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models inherited from previous grid searching. \n",
    "lr_model = LogisticRegression(penalty = 'l1', C = 1)\n",
    "lr_model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = val_X.as_matrix()\n",
    "test_X = test_X.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_lr_pre = lr_model.predict_proba(val_X)\n",
    "\n",
    "y_test_lr_pre = lr_model.predict_proba(test_X)\n",
    "\n",
    "w = (40000-1786)/train.shape[0]\n",
    "avgCTR = sum(train.click)/train.shape[0]\n",
    "\n",
    "test_score_lr = y_test_lr_pre[:,1]/(y_test_lr_pre[:,1]+(1-y_test_lr_pre[:,1])/w)\n",
    "valid_score_lr = y_valid_lr_pre[:,1]/(y_valid_lr_pre[:,1]+(1-y_valid_lr_pre[:,1])/w)\n",
    "\n",
    "validation = validation.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=600,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgboost.XGBClassifier(max_depth = 5, n_estimators = 600, learning_rate = 0.1, objective = 'binary:logistic')\n",
    "xgb_model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_xgb_pre = xgb_model.predict_proba(X_val)\n",
    "\n",
    "X_test = X_test.as_matrix()\n",
    "y_test_xgb_pre = xgb_model.predict_proba(X_test)\n",
    "\n",
    "w = (40000-1786)/train.shape[0]\n",
    "avgCTR = sum(train.click)/train.shape[0]\n",
    "\n",
    "test_score_xgb = y_test_xgb_pre[:,1]/(y_test_xgb_pre[:,1]+(1-y_test_xgb_pre[:,1])/w)\n",
    "valid_score_xgb = y_valid_xgb_pre[:,1]/(y_valid_xgb_pre[:,1]+(1-y_valid_xgb_pre[:,1])/w)\n",
    "\n",
    "validation = validation.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validationDataFrame(model, lambda_range = None, c_range=None, bid_range=None, strategy):\n",
    "    df = pd.DataFrame(columns=['parameter_c','parameter_lambda','impression','cost','clicks'])\n",
    "    iteration = 0\n",
    "    max_num = 0\n",
    "    max_bid = 0\n",
    "    cost = 0\n",
    "    best_lambda = 0\n",
    "    best_c = 0\n",
    "    \n",
    "    if model == \"xgb\":\n",
    "        valid_score == valid_score_xgb\n",
    "    else: \n",
    "        valid_score == vlaid_score_lr\n",
    "        \n",
    "        \n",
    "    if strategy == \"ortb_1\":\n",
    "        for c in c_range:\n",
    "            for l in lambda_range:\n",
    "                num_click = 0\n",
    "                utils = True\n",
    "                impression = 0\n",
    "                cost = 0\n",
    "                iteration += 1\n",
    "                size = validation.shape[0]\n",
    "                \n",
    "                for i in range(validation.shape[0]):\n",
    "                    b = np.sqrt(c / l * valid_score[i] + c ** 2) - c\n",
    "                    \n",
    "                    if b >= validation.payprice[i] and utils:\n",
    "                        cost = cost + validation.payprice[i]\n",
    "                        if cost > 6250000:\n",
    "                            cost = cost - validation.payprice[i]\n",
    "                            utils = False\n",
    "                            break\n",
    "                        num_click = num_click + validation.click[i]\n",
    "                        impression = impression + 1\n",
    "            \n",
    "                df.loc[iteration,'clicks'] = num_click\n",
    "                df.loc[iteration,'cost'] = cost/1000\n",
    "                df.loc[iteration,'impression'] = impression\n",
    "                \n",
    "                if num_click > max_num:\n",
    "                    max_num = num_click\n",
    "                    best_lambda = m\n",
    "                    best_c = c\n",
    "        \n",
    "                df.loc[iteration,'Parameter_c'] = best_c\n",
    "                df.loc[iteration,'Parameter_lambda'] = best_lambda\n",
    "            \n",
    "    elif strategy == \"ortb_2\":\n",
    "        for c in c_range:\n",
    "            for l in lambda_range:\n",
    "                num_click = 0\n",
    "                utils = True\n",
    "                impression = 0\n",
    "                cost = 0\n",
    "                iteration += 1\n",
    "                size = validation.shape[0]\n",
    "                \n",
    "                for i in range(validation.shape[0]):\n",
    "                    expr=(valid_score[i]+np.sqrt((c**2) * (m**2)+valid_score[i]**2))/(c*m)\n",
    "                    b=(expr**(1/3)-expr**(-1/3))*c\n",
    "                    \n",
    "                    if b >= validation.payprice[i] and utils:\n",
    "                        cost = cost + validation.payprice[i]\n",
    "                        if cost > 6250000:\n",
    "                            cost = cost - validation.payprice[i]\n",
    "                            utils = False\n",
    "                            break\n",
    "                        num_click = num_click + validation.click[i]\n",
    "                        impression = impression + 1\n",
    "            \n",
    "                df.loc[iteration,'clicks'] = num_click\n",
    "                df.loc[iteration,'cost'] = cost/1000\n",
    "                df.loc[iteration,'impression'] = impression\n",
    "                \n",
    "                if num_click > max_num:\n",
    "                    max_num = num_click\n",
    "                    best_lambda = m\n",
    "                    best_c = c\n",
    "        \n",
    "                df.loc[iteration,'Parameter_c'] = best_c\n",
    "                df.loc[iteration,'Parameter_lambda'] = best_lambda         \n",
    "                     \n",
    "    elif strategy == \"quadratic\":\n",
    "        for bid_base in np.arange(3,300, 3):\n",
    "            num_click = 0\n",
    "            utils = True\n",
    "            impression = 0\n",
    "            cost = 0\n",
    "            iteration += 1\n",
    "            size = validation.shape[0]\n",
    "            \n",
    "            for i in range(validation.shape[0]):\n",
    "                bid = bid_base*(valid_score[i]/avgCTR)**2\n",
    "                \n",
    "                if b >= validation.payprice[i] and utils:\n",
    "                    cost = cost + validation.payprice[i]\n",
    "                    if cost > 6250000:\n",
    "                        cost = cost - validation.payprice[i]\n",
    "                        utils = False\n",
    "                        break\n",
    "                    num_click = num_click + validation.click[i]\n",
    "                    impression = impression + 1\n",
    "                \n",
    "                df.loc[iteration,'bid_base'] = bid_base\n",
    "                df.loc[iteration,'clicks'] = num_click\n",
    "                df.loc[iteration,'cost'] = cost/1000\n",
    "                df.loc[iteration,'impression'] = impression\n",
    "                \n",
    "                if num_click > max_num:\n",
    "                #print('increase')\n",
    "                    max_num = num_click\n",
    "                    max_bid = bid_base\n",
    "                    \n",
    "                    \n",
    "    else:\n",
    "        for bid_base in np.arange(3,300, 3):\n",
    "            num_click = 0\n",
    "            utils = True\n",
    "            impression = 0\n",
    "            cost = 0\n",
    "            iteration += 1\n",
    "            size = validation.shape[0]\n",
    "            \n",
    "            for i in range(validation.shape[0]):\n",
    "                bid = bid_base*np.exp(valid_score[i]/avgCTR)\n",
    "                \n",
    "                if b >= validation.payprice[i] and utils:\n",
    "                    cost = cost + validation.payprice[i]\n",
    "                    if cost > 6250000:\n",
    "                        cost = cost - validation.payprice[i]\n",
    "                        utils = False\n",
    "                        break\n",
    "                    num_click = num_click + validation.click[i]\n",
    "                    impression = impression + 1\n",
    "                \n",
    "                df.loc[iteration,'bid_base'] = bid_base\n",
    "                df.loc[iteration,'clicks'] = num_click\n",
    "                df.loc[iteration,'cost'] = cost/1000\n",
    "                df.loc[iteration,'impression'] = impression\n",
    "                \n",
    "                if num_click > max_num:\n",
    "                #print('increase')\n",
    "                    max_num = num_click\n",
    "                    max_bid = bid_base\n",
    "        \n",
    "                \n",
    "    \n",
    "    #print(num_click)\n",
    "    \n",
    "        \n",
    "    df['CTR'] = df['clicks']/df['Imps']\n",
    "    df['eCPC'] = df['spend']/df['clicks']\n",
    "    df['CPM'] = df['spend']*1000/df['Imps']\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORTB Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORTB1+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion\n",
    "# b = sqrt(c/lambda * pctr + c^2) - c\n",
    "lambda_range = [1e-8,5e-8,1e-7,5e-7,1e-6,5e-6,1e-5,5e-5,1e-4,5e-4]\n",
    "c_range= np.linspace(0.1, 100, 200)\n",
    "eval_ORTB_1_lr = validationDataFrame(model = \"lr\", lambda_range=lambda_range, c_range=c_range, strategy=\"ortb_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_c</th>\n",
       "      <th>best_lambda</th>\n",
       "      <th>Imps</th>\n",
       "      <th>spend</th>\n",
       "      <th>clicks</th>\n",
       "      <th>CTR</th>\n",
       "      <th>eCPC</th>\n",
       "      <th>CPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>93.9455</td>\n",
       "      <td>5e-06</td>\n",
       "      <td>125939</td>\n",
       "      <td>6247.15</td>\n",
       "      <td>163</td>\n",
       "      <td>0.00129428</td>\n",
       "      <td>38.3261</td>\n",
       "      <td>49.6046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>93.9455</td>\n",
       "      <td>5e-06</td>\n",
       "      <td>125840</td>\n",
       "      <td>6249.85</td>\n",
       "      <td>163</td>\n",
       "      <td>0.0012953</td>\n",
       "      <td>38.3426</td>\n",
       "      <td>49.665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      best_c best_lambda    Imps    spend clicks         CTR     eCPC      CPM\n",
       "936  93.9455       5e-06  125939  6247.15    163  0.00129428  38.3261  49.6046\n",
       "946  93.9455       5e-06  125840  6249.85    163   0.0012953  38.3426   49.665"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ORTB_1_lr.iloc[np.where(eval_ORTB_1_lr.clicks == eval_ORTB_1_lr.clicks.max())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORTB2+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_range = [1e-8,5e-8,1e-7,5e-7,1e-6,5e-6,1e-5,5e-5,1e-4,5e-4]\n",
    "c_range= np.linspace(0.1, 100, 200)\n",
    "eval_ORTB_2_lr = validationDataFrame(model = \"lr\", lambda_range=lambda_range, c_range=c_range, strategy=\"ortb_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ORTB_2_lr.iloc[np.where(eval_ORTB_2_lr.clicks == eval_ORTB_2_lr.clicks.max())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORTB1+XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_range = [1e-8,5e-8,1e-7,5e-7,1e-6,5e-6,1e-5,5e-5,1e-4,5e-4]\n",
    "c_range= np.linspace(0.1, 100, 200)\n",
    "eval_ORTB_1_xgb = validationDataFrame(model = \"xgb\", lambda_range=lambda_range, c_range=c_range, strategy=\"ortb_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ORTB_1_xgb.iloc[np.where(eval_ORTB_1_xgb.clicks == eval_ORTB_1_xgb.clicks.max())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORTB2+XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_range = [1e-8,5e-8,1e-7,5e-7,1e-6,5e-6,1e-5,5e-5,1e-4,5e-4]\n",
    "c_range= np.linspace(0.1, 100, 200)\n",
    "eval_ORTB_2_xgb = validationDataFrame(model = \"xgb\", lambda_range=lambda_range, c_range=c_range, strategy=\"ortb_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ORTB_2_xgb.iloc[np.where(eval_ORTB_2_xgb.clicks == eval_ORTB_2_xgb.clicks.max())[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other bidding strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic bidding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "#bid = base_bid * (pCTR / avgCTR)^2\n",
    "bidbase = np.arange(3,150,3)\n",
    "eval_lr_quad = validationDataFrame(model = \"lr\", bid_base = bidbase, strategy=\"quadratic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_lr_quad.iloc[np.where(eval_lr_quad.clicks == eval_lr_quad.clicks.max())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidbase = np.arange(3,150,3)\n",
    "eval_xgb_quad = validationDataFrame(model = \"xgb\", bid_base = bidbase, strategy=\"quadratic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_xgb_quad.iloc[np.where(eval_xgb_quad.clicks == eval_xgb_quad.clicks.max())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential bidding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR EXP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "#bid = base_bid * exp(pCTR / avgCTR)\n",
    "bidbase = np.arange(3,30,3)\n",
    "eval_lr_exp = validationDataFrame(model = \"lr\", bid_base = bidbase, strategy=\"exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_lr_exp.iloc[np.where(eval_lr_exp.clicks == eval_lr_exp.clicks.max())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB EXP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "#bid = base_bid * exp(pCTR / avgCTR)\n",
    "bidbase = np.arange(3,30,3)\n",
    "eval_xgb_exp = validationDataFrame(model = \"xgb\", bid_base = bidbase, strategy=\"exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_xgb_exp.iloc[np.where(eval_xgb_exp.clicks == eval_xgb_exp.clicks.max())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorityVoteClassifier(BaseEstimator,\n",
    "                            ClassifierMixin):\n",
    "    def __init__(self, classifiers,\n",
    "                 vote='classlabel', weights=None):\n",
    "        self.classifiers = classifiers\n",
    "        self.named_classifiers = {key: value for\n",
    "                                  key, value in\n",
    "                                  _name_estimators(classifiers)}\n",
    "        self.vote = vote\n",
    "        self.weights = weights\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):     \n",
    "        self.lablenc_ = LabelEncoder()\n",
    "        self.lablenc_.fit(y)\n",
    "        self.classes_ = self.lablenc_.classes_\n",
    "        self.classifiers_ = []\n",
    "        for clf in self.classifiers:\n",
    "            fitted_clf = clone(clf).fit(X,\n",
    "                              self.lablenc_.transform(y))\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.vote == 'probability':\n",
    "            maj_vote = np.argmax(self.predict_proba(X),\n",
    "                                 axis=1)\n",
    "        else: # 'classlabel' vote\n",
    "             # Collect results from clf.predict calls\n",
    "            predictions = np.asarray([clf.predict(X)\n",
    "                                      for clf in\n",
    "                                      self.classifiers_]).T\n",
    "            maj_vote = np.apply_along_axis(\n",
    "                           lambda x:\n",
    "                           np.argmax(np.bincount(x,\n",
    "                                        weights=self.weights)),\n",
    "                           axis=1,\n",
    "                           arr=predictions)\n",
    "\n",
    "        maj_vote = self.lablenc_.inverse_transform(maj_vote)\n",
    "        return maj_vote\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        probas = np.asarray([clf.predict_proba(X)\n",
    "                             for clf in self.classifiers_])\n",
    "        avg_proba = np.average(probas,\n",
    "                               axis=0, weights=self.weights)\n",
    "        return avg_proba\n",
    "            \n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\" Get classifier parameter names for GridSearch\"\"\"\n",
    "        if not deep:\n",
    "            return super(MajorityVoteClassifier,\n",
    "                         self).get_params(deep=False)\n",
    "        else:\n",
    "            out = self.named_classifiers.copy()\n",
    "            for name, step in\\\n",
    "                    six.iteritems(self.named_classifiers):\n",
    "                for key, value in six.iteritems(\n",
    "                        step.get_params(deep=True)):\n",
    "                    out['%s__%s' % (name, key)] = value\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_clf = MajorityVoteClassifier(classifiers = [lr_model,xgb_model])\n",
    "clf_labels = [\"Logistic Regression\", \"XGBoost\"]\n",
    "clf_labels += ['Majority Voting']\n",
    "all_clf = [lr_model, xgb_model, mv_clf]\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator = clf,\n",
    "                             X = X_train,\n",
    "                             y = Y_train,\n",
    "                             cv = 3,\n",
    "                             scoring = 'roc_auc')\n",
    "    print(\"ROC AUC: %0.4f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pre = mv_clf.predict_proba(X_val)\n",
    "\n",
    "y_test_pre = mv_clf.predict_proba(X_test)\n",
    "\n",
    "w = (40000-1786)/train.shape[0]\n",
    "avgCTR = sum(train.click)/train.shape[0]\n",
    "\n",
    "test_score_ensembled = y_test_pre[:,1]/(y_test_pre[:,1]+(1-y_test_pre[:,1])/w)\n",
    "valid_score_ensembled = y_valid_pre[:,1]/(y_valid_pre[:,1]+(1-y_valid_pre[:,1])/w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion\n",
    "# bid = sqrt(c/lambda pctr + c^2) - c\n",
    "lambda_range = [1e-8,5e-8,1e-7,5e-7,1e-6,5e-6,1e-5,5e-5,1e-4,5e-4]\n",
    "c_range= np.linspace(0.1, 100, 200)\n",
    "eval_ORTB_1_ensemble = validationDataFrame(model = \"xgb\", lambda_range=lambda_range, c_range=c_range, strategy=\"ortb_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ORTB_1_ensemble.iloc[np.where(eval_ORTB_1_ensemble.clicks == eval_ORTB_1_ensemble.clicks.max())[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
